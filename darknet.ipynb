{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from base import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link Doesn't work!\n",
    "model_paths = {\n",
    "    'darknet19': 'https://s3.ap-northeast-2.amazonaws.com/deepbaksuvision/darknet19-deepBakSu-e1b3ec1e.pth'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAvgPool2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.data.size(0)\n",
    "        C = x.data.size(1)\n",
    "        H = x.data.size(2)\n",
    "        W = x.data.size(3)\n",
    "        x = F.avg_pool2d(x, (H, W))\n",
    "        x = x.view(N, C)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet19(BaseModel):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(Darknet19, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "        ('layer1', nn.Sequential(OrderedDict([\n",
    "            ('conv1_1', nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn1_1', nn.BatchNorm2d(32)),\n",
    "            ('leaky1_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool1', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer2', nn.Sequential(OrderedDict([\n",
    "            ('conv2_1', nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn2_1', nn.BatchNorm2d(64)),\n",
    "            ('leaky2_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool2', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer3', nn.Sequential(OrderedDict([\n",
    "            ('conv3_1', nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn3_1', nn.BatchNorm2d(128)),\n",
    "            ('leaky3_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv3_2', nn.Conv2d(128, 64, kernel_size=1, stride=1, padding=0, bias=False)),\n",
    "            ('bn3_2', nn.BatchNorm2d(64)),\n",
    "            ('leaky3_2', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv3_3', nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn3_3', nn.BatchNorm2d(128)),\n",
    "            ('leaky3_3', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool3', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer4', nn.Sequential(OrderedDict([\n",
    "            ('conv4_1', nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn4_1', nn.BatchNorm2d(256)),\n",
    "            ('leaky4_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv4_2', nn.Conv2d(256, 128, kernel_size=1, stride=1, padding=0, bias=False)),\n",
    "            ('bn4_2', nn.BatchNorm2d(128)),\n",
    "            ('leaky4_2', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv4_3', nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn4_3', nn.BatchNorm2d(256)),\n",
    "            ('leaky4_3', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool4', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer5', nn.Sequential(OrderedDict([\n",
    "            ('conv5_1', nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn5_1', nn.BatchNorm2d(512)),\n",
    "            ('leaky5_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv5_2', nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0, bias=False)),\n",
    "            ('bn5_2', nn.BatchNorm2d(256)),\n",
    "            ('leaky5_2', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv5_3', nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn5_3', nn.BatchNorm2d(512)),\n",
    "            ('leaky5_3', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv5_4', nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=1, bias=False)),\n",
    "            ('bn5_4', nn.BatchNorm2d(256)),\n",
    "            ('leaky5_4', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv5_5', nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn5_5', nn.BatchNorm2d(512)),\n",
    "            ('leaky5_5', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool5', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer6', nn.Sequential(OrderedDict([\n",
    "            ('conv6_1', nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn6_1', nn.BatchNorm2d(1024)),\n",
    "            ('leaky6_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv6_2', nn.Conv2d(1024, 512, kernel_size=1, stride=1, padding=0, bias=False)),\n",
    "            ('bn6_2', nn.BatchNorm2d(512)),\n",
    "            ('leaky6_2', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv6_3', nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn6_3', nn.BatchNorm2d(1024)),\n",
    "            ('leaky6_3', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv6_4', nn.Conv2d(1024, 512, kernel_size=1, stride=1, padding=1, bias=False)),\n",
    "            ('bn6_4', nn.BatchNorm2d(512)),\n",
    "            ('leaky6_4', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv6_5', nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn6_5', nn.BatchNorm2d(1024)),\n",
    "            ('leaky6_5', nn.LeakyReLU(0.1, inplace=True))\n",
    "        ])))\n",
    "        ]))\n",
    "\n",
    "        self.classifier = nn.Sequential(OrderedDict([\n",
    "        ('conv7_1', nn.Conv2d(1024, 1000, kernel_size=(1, 1), stride=(1, 1))),\n",
    "        ('globalavgpool', GlobalAvgPool2d()),\n",
    "        ('softmax', nn.Softmax(dim=1))\n",
    "        ]))\n",
    "\n",
    "        if pretrained:\n",
    "            # self.load_state_dict(model_zoo.load_url(model_paths['darknet19'],  progress=True))\n",
    "            self.load_weight()\n",
    "            print('Model is loaded')\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "    def load_weight(self):\n",
    "        weight_file = 'weights/darknet19-deepBakSu-e1b3ec1e.pth'\n",
    "        assert len(torch.load(weight_file).keys()) == len(self.state_dict().keys())\n",
    "        dic = {}\n",
    "        for now_keys, values in zip(self.state_dict().keys(), torch.load(weight_file).values()):\n",
    "            dic[now_keys]=values\n",
    "        self.load_state_dict(dic)\n",
    "        print('Weights are loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Weights are loaded!\nModel is loaded\n"
    }
   ],
   "source": [
    "model = Darknet19(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 1's Convolutional layer weights.\n",
    "firstWeightMatrix = model.features[0][0].weight\n",
    "firstBiasMatrix = model.features[0][0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "864"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "sum(p.numel() for p in model.features[0][0].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstBiasMatrix # Bias is set to false so no bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "20842376"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np        \n",
    "\n",
    "weights = open('conv_1_1.csv', 'ab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('conv_1_1.csv', firstWeightMatrix.detach().numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "32"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "model.features[0][0].out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.features[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([-2.3214601e-03, -2.5296986e-01,  1.1893848e-03,  2.3869975e-03,\n        2.2873398e-02, -1.3856249e-03, -3.0809397e-01,  1.1708887e-01,\n       -3.0102493e-04, -1.4464438e-02, -4.5391001e-02,  1.8429115e-01,\n       -2.8679994e-01,  1.9463764e-01,  6.2633986e-03,  2.0220485e-03,\n        5.5335030e-02,  3.7532397e-02, -1.8442741e-02, -3.1703014e-03,\n        4.7915992e-03,  3.3819050e-02, -2.2025496e-01, -3.4106191e-02,\n        1.0814303e-01,  5.4634456e-02, -2.0843312e-01, -5.0900027e-04,\n       -1.7058287e-02, -1.9609613e-02,  2.8884465e-01, -4.7691960e-02],\n      dtype=float32)"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "a.running_mean.detach().numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(a, nn.Conv2d):\n",
    "    name = \"Convolution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Convolution'"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([False, False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False, False,\n        False, False])"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "model.features[0][1].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Parameter containing:\ntensor([ -1.9168,  -1.7893,   0.8074,   2.1464,   1.9664,   0.7599,  -6.7155,\n         -3.2311,  -1.1955,  -2.3681,  -2.9968,  -6.5154, -10.2869,  -2.1426,\n          0.8042,   0.4698,   1.0785,   0.8214,   0.4473,  -2.4476,   0.6459,\n          0.7412,  -4.4340,   3.2402,  -1.3607,   1.3372,  -1.8851,  -3.2254,\n         -2.5978,   0.3849,  -7.8350,  -0.0251], requires_grad=True)"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "model.features[0][1].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([32])"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "model.features[0][1].bias.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([32])"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "model.features[0][1].weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Conv2d' object has no attribute 'input_channel'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a3045d3a185f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Conv2d' object has no attribute 'input_channel'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}